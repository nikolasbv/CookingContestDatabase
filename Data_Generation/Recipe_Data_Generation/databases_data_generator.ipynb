{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee3d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fuzzywuzzy import process, fuzz\n",
    "from fractions import Fraction\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e65ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./datasets_for_generator\"\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad8cfed",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "NATIONALITIES !!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43090a7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL generation complete. All insertion queries for images and nationalities have been saved.\n",
      "Last nationality ID used (total nationalities): 178\n"
     ]
    }
   ],
   "source": [
    "def load_and_prepare_data():\n",
    "    \n",
    "    flags_df = pd.read_csv(file_path + 'flags2.csv', delimiter=',', encoding='ISO-8859-1')\n",
    "    countries_df = pd.read_csv(file_path + 'countries.csv')\n",
    "\n",
    "    flags_df.rename(columns={'Country': 'Name', 'Flag_image_url': 'image'}, inplace=True)\n",
    "\n",
    "    merged_df = pd.merge(flags_df[['Name', 'image']], countries_df[['Name', 'Nationality']], on='Name', how='inner')\n",
    "    \n",
    "    merged_df = merged_df[merged_df['image'].notna() & (merged_df['image'] != '')]\n",
    "    \n",
    "    new_entries = pd.DataFrame({\n",
    "        'Name': ['United Kingdom', 'United States'],\n",
    "        'image': [\n",
    "            'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Flag_of_the_United_Kingdom_%281-2%29.svg/383px-Flag_of_the_United_Kingdom_%281-2%29.svg.png',\n",
    "            'https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Flag_of_the_United_States_%28DoS_ECA_Color_Standard%29.svg/383px-Flag_of_the_United_States_%28DoS_ECA_Color_Standard%29.svg.png'\n",
    "        ],\n",
    "        'Nationality': ['British', 'American']\n",
    "    })\n",
    "\n",
    "    merged_df = pd.concat([merged_df, new_entries], ignore_index=True)\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "nationality_dict = {}\n",
    "def generate_sql(merged_data):\n",
    "    sql_statements = []\n",
    "    image_id = 1 \n",
    "\n",
    "    for _, row in merged_data.iterrows():\n",
    "        image_sql = f\"\"\"INSERT INTO Image (image_url, description) VALUES ('{row['image']}', 'This is the flag of {row['Name']}');\"\"\"\n",
    "        sql_statements.append(image_sql)\n",
    "\n",
    "        nationality_sql = f\"\"\"INSERT INTO Nationality (name, image_id) VALUES ('{row['Nationality']}', {image_id});\"\"\"\n",
    "        sql_statements.append(nationality_sql)\n",
    "        \n",
    "        nationality_dict[image_id] = row['Nationality']\n",
    "\n",
    "        image_id += 1 \n",
    "\n",
    "    return sql_statements, image_id - 1 \n",
    "\n",
    "merged_data = load_and_prepare_data()\n",
    "\n",
    "sql_commands, last_nationality_id = generate_sql(merged_data)\n",
    "last_image_id = last_nationality_id\n",
    "\n",
    "with open(file_path + 'insert_data.sql', 'w', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "    file.write('\\n')\n",
    "\n",
    "print(\"SQL generation complete. All insertion queries for images and nationalities have been saved.\")\n",
    "print(f\"Last nationality ID used (total nationalities): {last_nationality_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905efa27",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "FOOD GROUPS!!!!!!!!!!!!!\n",
    "\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d732244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_group_dict = {\n",
    "    1: 'Spices and essential oils',\n",
    "    2: 'Coffee, tea and their products',\n",
    "    3: 'Preserved foods',\n",
    "    4: 'Sweeteners',\n",
    "    5: 'Fats and oils',\n",
    "    6: 'Milk, eggs and their products',\n",
    "    7: 'Meat and its products',\n",
    "    8: 'Fish and their products',\n",
    "    9: 'Cereals and their products',\n",
    "    10: 'Various foods of plant origin',\n",
    "    11: 'Products with sweeteners',\n",
    "    12: 'Various drinks'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f62e4701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All insertion queries for images and food groups have been saved to 'insert_data.sql'.\n"
     ]
    }
   ],
   "source": [
    "image_urls = [\n",
    "    \"https://www.ingredientsnetwork.com/47/product/127/23/83/herbs-and-spices.jpg\",\n",
    "    \"https://imageio.forbes.com/specials-images/imageserve/6393aebacd1e996dc7b13be0/Herbal-tea-and-espresso-coffee/0x0.jpg?format=jpg&crop=1325,993,x81,y0,safe&width=1440\",\n",
    "    \"https://thehouseandhomestead.com/wp-content/uploads/2019/07/Preserve-the-Harvest-Feature-Photo-2-1024x683.jpg\",\n",
    "    \"https://avitahealth.org/wp-content/uploads/2022/03/sweeteners-feature.jpg\",\n",
    "    \"https://mistafood.com/wp-content/uploads/2022/05/fats-oils-spreads-1200x675.jpeg\",\n",
    "    \"https://samsungfood.com/wp-content/uploads/2023/02/shutterstock_1679020255.jpg\",\n",
    "    \"https://images.ctfassets.net/3s5io6mnxfqz/5GlOYuzg0nApcehTPlbJMy/140abddf0f3f93fa16568f4d035cd5e6/AdobeStock_175165460.jpeg?w=828\",\n",
    "    \"https://www.qld.gov.au/__data/assets/image/0022/167422/varieties/Aggregation.jpg\",\n",
    "    \"https://fittify.in/cdn/shop/articles/4_adc6f48f-de12-4132-88ed-8a04805b8e4b.jpg?v=1673267293&width=1000\",\n",
    "    \"https://blogassets.vita4you.gr/blog-vita4you/wp-content/uploads/2023/01/%CE%A6%CF%85%CF%84%CE%B9%CE%BA%CE%AD%CF%82-%CF%80%CF%81%CF%89%CF%84%CE%B5%CE%90%CE%BD%CE%B5%CF%82-768x512.png\",\n",
    "    \"https://additive-free-living.s3.ap-southeast-2.amazonaws.com/wp-content/uploads/2023/07/11123357/Artificial-Sweeteners-800x533.jpg\",\n",
    "    \"https://fireandiceontobycreek.com/wp-content/uploads/2020/11/various-cocktail-drinks.jpg\"\n",
    "]\n",
    "\n",
    "sql_commands = []\n",
    "\n",
    "food_groups = [\n",
    "    'Spices and essential oils', 'Coffee, tea and their products', 'Preserved foods',\n",
    "    'Sweeteners', 'Fats and oils', 'Milk, eggs and their products', 'Meat and its products',\n",
    "    'Fish and their products', 'Cereals and their products', 'Various foods of plant origin',\n",
    "    'Products with sweeteners', 'Various drinks'\n",
    "]\n",
    "\n",
    "for idx, url in enumerate(image_urls, start=1):\n",
    "    last_image_id += 1\n",
    "    description = f\"\"\"This is an image for the food group {food_groups[idx-1]}.\"\"\"\n",
    "    image_sql = f\"\"\"INSERT INTO Image (image_url, description) VALUES ('{url}', '{description}');\"\"\"\n",
    "    sql_commands.append(image_sql)\n",
    "\n",
    "\n",
    "descriptions = [\n",
    "    'Essential for flavoring and seasoning a variety of dishes.',\n",
    "    'Includes all varieties of coffee and tea products.',\n",
    "    'Foods processed to ensure longer shelf life.',\n",
    "    'Natural and artificial substances used to sweeten food.',\n",
    "    'Essential cooking mediums and flavor enhancers.',\n",
    "    'Dairy products and eggs used in a multitude of recipes.',\n",
    "    'All types of meat products including processed meats.',\n",
    "    'Includes all fish and seafood items.',\n",
    "    'Staple ingredients derived from various grains.',\n",
    "    'Encompasses a diverse range of plant-based foods.',\n",
    "    'Foods specifically containing added sweeteners.',\n",
    "    'Includes a variety of beverages.'\n",
    "]\n",
    "\n",
    "identities = ['Spice', 'Beverage', 'Preserved', 'Sweetener', 'Fat', 'Dairy', 'Meat', 'Seafood', 'Cereal', 'Plant-Based', 'Sweetened', 'Drink']\n",
    "\n",
    "for idx, (group, desc, identity) in enumerate(zip(food_groups, descriptions, identities), start=1):\n",
    "    group_sql = f\"\"\"INSERT INTO Food_Group (name, description, image_id, group_identity) VALUES ('{group}', '{desc}', {last_image_id - 12 + idx}, '{identity}');\"\"\"\n",
    "    sql_commands.append(group_sql)\n",
    "\n",
    "with open(file_path + 'insert_data.sql', 'a', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "    file.write('\\n')\n",
    "\n",
    "print(\"All insertion queries for images and food groups have been saved to 'insert_data.sql'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf020074",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "EQUIPMENET !!!!!!!!!!!!!\n",
    "\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3a549ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_image_and_paragraph(page_url):\n",
    "    response = requests.get(page_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    figure = soup.find('figure', {'typeof': 'mw:File/Thumb'})\n",
    "    image_url = None\n",
    "    if figure:\n",
    "        img_tag = figure.find('img')\n",
    "        if img_tag and 'src' in img_tag.attrs:\n",
    "            image_url = 'https:' + img_tag['src']\n",
    "\n",
    "    first_paragraph = None\n",
    "    for p in soup.find_all('p'):\n",
    "        if p.text.strip():\n",
    "            for sup in p.find_all('sup'):\n",
    "                sup.decompose()\n",
    "            first_paragraph = ' '.join(p.text.strip().split())\n",
    "            break\n",
    "\n",
    "    return image_url, first_paragraph\n",
    "\n",
    "def extract_images_and_paragraphs_from_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        html_content = file.read()\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        links = soup.find_all('a')\n",
    "\n",
    "        details = []\n",
    "        for link in links:\n",
    "            href = link.get('href')\n",
    "            if href and href.startswith('/wiki/') and not 'redlink=1' in href:\n",
    "                full_url = 'https://en.wikipedia.org' + href\n",
    "                image_url, description = get_first_image_and_paragraph(full_url)\n",
    "                name = href[6:].replace('_', ' ')\n",
    "                \n",
    "                if image_url and description:\n",
    "                    details.append((name, image_url, description))\n",
    "\n",
    "    return details\n",
    "\n",
    "def generate_sql_for_equipment(equipment_details, last_image_id, equipment_dict):\n",
    "    sql_commands = []\n",
    "    image_id = last_image_id \n",
    "    equipment_id = 1\n",
    "\n",
    "    for name, image_url, manual in equipment_details:\n",
    "        \n",
    "        if name in equipment_dict.values() or name == 'Saut%C3%A9 pan':\n",
    "            continue\n",
    "            \n",
    "        image_id += 1\n",
    "        safe_manual = manual.replace('\"', '\\\\\"')\n",
    "        #image_sql = f'INSERT INTO Image (image_url, description) VALUES (\"{image_url}\", \"This is an image for {name}\");'\n",
    "        #equipment_sql = f'INSERT INTO Equipment (name, manual, image_id) VALUES (\"{name}\", \"{safe_manual}\", {image_id});'\n",
    "        image_sql = f\"\"\"INSERT INTO Image (image_url, description) VALUES (\"{image_url}\", \"This is an image for {name}\");\"\"\"\n",
    "        equipment_sql = f\"\"\"INSERT INTO Equipment (name, manual, image_id) VALUES (\"{name}\", \"{safe_manual}\", {image_id});\"\"\"\n",
    "        \n",
    "        sql_commands.append(image_sql)\n",
    "        sql_commands.append(equipment_sql)\n",
    "        \n",
    "        equipment_dict[equipment_id] = name \n",
    "        equipment_id += 1  \n",
    "\n",
    "    return image_id, sql_commands, equipment_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc7f58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchenware_details = extract_images_and_paragraphs_from_file(file_path + 'kitchenware.txt')\n",
    "cookware_details = extract_images_and_paragraphs_from_file(file_path + 'cookware.txt')\n",
    "\n",
    "equipment_details = kitchenware_details + cookware_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "49db51dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All insertion queries for equipment images and equipment details have been saved to 'insert_data.sql'.\n"
     ]
    }
   ],
   "source": [
    "equipment_dict = {}\n",
    "last_image_id, sql_commands, equipment_dict= generate_sql_for_equipment(equipment_details, last_image_id, equipment_dict)\n",
    "\n",
    "with open(file_path + 'insert_data.sql', 'a', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "    file.write('\\n')\n",
    "\n",
    "print(\"All insertion queries for equipment images and equipment details have been saved to 'insert_data.sql'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8248b7c",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "INGREDIENTS !!!!!!!!!!!!!\n",
    "\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31d8accb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "food_df = file_path + 'Food.json'\n",
    "base_url = \"https://foodb.ca/system/foods/pictures/\"\n",
    "data = []\n",
    "\n",
    "with open(food_df, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            entry = json.loads(line)\n",
    "            if 'id' in entry and 'name' in entry:\n",
    "                data.append(entry)\n",
    "        except json.JSONDecodeError:\n",
    "            continue \n",
    "            \n",
    "foods_df = pd.DataFrame(data)\n",
    "if 'id' in foods_df.columns:\n",
    "    foods_df['image_url'] = base_url + foods_df['id'].astype(str) + '/full/' + foods_df['id'].astype(str) + '.png'\n",
    "\n",
    "\n",
    "for entry in data:\n",
    "    food_id = entry['id']\n",
    "    food_name = entry['name']\n",
    "    image_url = f\"{base_url}{food_id}/full/{food_id}.png\"\n",
    "    #print(f\"Name: {food_name}, Image URL: {image_url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "961b8e4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "category_map = {\n",
    "    'Herbs and Spices': 'Spices and essential oils',\n",
    "    'Vegetables': 'Various foods of plant origin',\n",
    "    'Fruits': 'Various foods of plant origin',\n",
    "    'Nuts': 'Various foods of plant origin',\n",
    "    'Cereals and cereal products': 'Cereals and their products',\n",
    "    'Pulses': 'Various foods of plant origin',\n",
    "    'Teas': 'Coffee, tea and their products',\n",
    "    'Gourds': 'Various foods of plant origin',\n",
    "    'Coffee and coffee products': 'Coffee, tea and their products',\n",
    "    'Soy': 'Various foods of plant origin',\n",
    "    'Cocoa and cocoa products': 'Various foods of plant origin',\n",
    "    'Beverages': 'Various drinks',\n",
    "    'Aquatic foods': 'Fish and their products',\n",
    "    'Animal foods': 'Meat and its products',\n",
    "    'Milk and milk products': 'Milk, eggs and their products',\n",
    "    'Eggs': 'Milk, eggs and their products',\n",
    "    'Confectioneries': 'Preserved foods',\n",
    "    'Baking goods': 'Various foods of plant origin',\n",
    "    'Dishes': 'Various foods of plant origin',\n",
    "    'Snack foods': 'Various foods of plant origin',\n",
    "    'Baby foods': 'Various foods of plant origin',\n",
    "    'Fats and oils': 'Fats and oils',\n",
    "    'Unclassified': 'Various foods of plant origin',\n",
    "    'None': 'Various foods of plant origin'\n",
    "}\n",
    "\n",
    "foods_df['mapped_group'] = foods_df['food_group'].map(category_map)\n",
    "foods_df['mapped_group'] = foods_df['mapped_group'].fillna('Various foods of plant origin')\n",
    "\n",
    "\n",
    "#print(foods_df[['food_group', 'mapped_group']].head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62dab6e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "food_calories_df = pd.read_csv(file_path + 'food_calories.txt', sep='\\t')\n",
    "final_food_df = food_calories_df.copy()\n",
    "\n",
    "name_to_id_dict = {v: k for k, v in food_group_dict.items()}\n",
    "\n",
    "def find_best_match(food_item, search_df):\n",
    "    # Full name match first\n",
    "    matches = process.extractOne(food_item, search_df['name'], scorer=fuzz.token_sort_ratio)\n",
    "    if matches[1] >= 90: \n",
    "        matched_row = search_df[search_df['name'] == matches[0]]\n",
    "        return matched_row['image_url'].iloc[0], matched_row['mapped_group'].iloc[0]\n",
    "    \n",
    "    words = food_item.split()\n",
    "    for word in words:\n",
    "        matches = process.extractOne(word, search_df['name'], scorer=fuzz.token_sort_ratio)\n",
    "        if matches[1] >= 70: \n",
    "            matched_row = search_df[search_df['name'] == matches[0]]\n",
    "            if not matched_row.empty:\n",
    "                return matched_row['image_url'].iloc[0], matched_row['mapped_group'].iloc[0]\n",
    "    \n",
    "    return \"https://upload.wikimedia.org/wikipedia/commons/1/14/No_Image_Available.jpg\", \"Various foods of plant origin\" \n",
    "\n",
    "\n",
    "final_food_df[['image_url', 'food_group']] = final_food_df['Food'].apply(\n",
    "    lambda x: find_best_match(x, foods_df)\n",
    ").apply(pd.Series) \n",
    "\n",
    "final_food_df['food_group'] = final_food_df['food_group'].map(name_to_id_dict)\n",
    "\n",
    "#print(final_food_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f59c3d97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All insertion queries for ingredient images and ingredients have been saved to 'insert_data.sql'.\n"
     ]
    }
   ],
   "source": [
    "def generate_ingredient_sql(df, last_image_id):\n",
    "    sql_commands = []\n",
    "    image_id = last_image_id \n",
    "    ingredient_id = 1 \n",
    "    ingredient_dict = {}\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        safe_food = row['Food'].replace(\"'\", \" \")\n",
    "        safe_food = safe_food.replace(\"’\", \" \")\n",
    "        image_description = f\"This is an image for {safe_food}\"\n",
    "        image_sql = f\"\"\"INSERT INTO Image (image_url, description) VALUES ('{row['image_url']}', '{image_description}');\"\"\"\n",
    "        sql_commands.append(image_sql)\n",
    "        \n",
    "        avg_grams = calculate_avg_grams(row['Share']) \n",
    "        \n",
    "        image_id += 1  \n",
    "        ingredient_sql = f\"\"\"INSERT INTO Ingredient (\n",
    "            name, kcal_per_100, image_id, food_group_id, avg_grams\n",
    "        ) VALUES (\n",
    "            '{safe_food}', {row['Calories/100g-ml']}, {image_id}, {row['food_group']}, {avg_grams}\n",
    "        );\"\"\"\n",
    "        sql_commands.append(ingredient_sql)\n",
    "\n",
    "        ingredient_dict[safe_food] = ingredient_id\n",
    "        ingredient_id += 1 \n",
    "        \n",
    "    return image_id, sql_commands, ingredient_dict\n",
    "\n",
    "def calculate_avg_grams(share_description):\n",
    "    \n",
    "    default_grams = 100\n",
    "    \n",
    "    match = re.search(r'(\\d+|[\\d/]+) (cup|piece|fruit|boxes|slice|tsp)[s]* \\((\\d+)gr\\)', share_description)\n",
    "    if match:\n",
    "        servings = match.group(1)\n",
    "        grams = int(match.group(3))\n",
    "        try:\n",
    "            servings = float(Fraction(servings))\n",
    "        except ValueError:\n",
    "            servings = float(servings)\n",
    "        return grams / servings if servings > 0 else grams\n",
    "\n",
    "    match = re.search(r'(\\d+)gr', share_description)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "\n",
    "    match = re.search(r'(\\d+)ml', share_description)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    \n",
    "    return default_grams\n",
    "\n",
    "image_id, sql_commands, ingredient_dict = generate_ingredient_sql(final_food_df, last_image_id)\n",
    "last_image_id = image_id\n",
    "\n",
    "with open(file_path + 'insert_data.sql', 'a', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "    file.write('\\n')\n",
    "\n",
    "print(\"All insertion queries for ingredient images and ingredients have been saved to 'insert_data.sql'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e11ce5d",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "ADMIN !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b7f13d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admin insertion queries have been saved to 'insert_data.sql'.\n"
     ]
    }
   ],
   "source": [
    "fake = Faker()\n",
    "\n",
    "sql_commands = []\n",
    "\n",
    "first_name = fake.first_name_male()\n",
    "last_name = fake.last_name_male()\n",
    "username = \"chef_botakis\"\n",
    "password = \"12345678\"\n",
    "\n",
    "admin_sql = f\"\"\"INSERT INTO Administrator (first_name, last_name, username, password) VALUES ('{first_name}', '{last_name}', '{username}', '{password}');\"\"\"\n",
    "user_sql = f\"\"\"CREATE USER '{username}' IDENTIFIED BY '{password}';\"\"\"\n",
    "role_sql = f\"\"\"GRANT 'Administrator' TO '{username}';\"\"\"\n",
    "set_role = f\"\"\"SET DEFAULT ROLE \"Administrator\" FOR '{username}';\"\"\"\n",
    "sql_commands.append(admin_sql)\n",
    "sql_commands.append(user_sql)\n",
    "sql_commands.append(role_sql)\n",
    "sql_commands.append(set_role)\n",
    "\n",
    "with open(file_path + 'insert_data.sql', 'a', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "    file.write('\\n')\n",
    "\n",
    "print(\"Admin insertion queries have been saved to 'insert_data.sql'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ae0909",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "COOKS !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47347a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cook insertion queries have been saved to 'insert_data.sql'.\n"
     ]
    }
   ],
   "source": [
    "male_img_base_url = \"https://xsgames.co/randomusers/assets/avatars/male/\"\n",
    "female_img_base_url = \"https://xsgames.co/randomusers/assets/avatars/female/\"\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def determine_ranking(years):\n",
    "    if years > 20:\n",
    "        return 'chef'\n",
    "    elif years > 15:\n",
    "        return 'sous chef'\n",
    "    elif years > 10:\n",
    "        return 'cook A'\n",
    "    elif years > 5:\n",
    "        return 'cook B'\n",
    "    else:\n",
    "        return 'cook C'\n",
    "\n",
    "\n",
    "def generate_cooks(num_males, num_females, male_img_base_url, female_img_base_url, last_image_id):\n",
    "    sql_commands = []\n",
    "    image_id = last_image_id\n",
    "    \n",
    "    # create one dummy user for testing\n",
    "    first_name = fake.first_name_male()\n",
    "    last_name = fake.last_name_male()\n",
    "    contact_number = fake.phone_number()\n",
    "    date_of_birth = fake.date_of_birth(minimum_age=18, maximum_age=65).isoformat()\n",
    "    years_of_experience = random.randint(0, 30)\n",
    "    ranking = determine_ranking(years_of_experience)\n",
    "    username = \"aplos_botakis\"\n",
    "    password = \"12345678\"\n",
    "        \n",
    "    image_url = f\"{male_img_base_url}1.jpg\"\n",
    "    image_description = f\"This is an image for cook {first_name} {last_name}\"\n",
    "    image_sql = f\"INSERT INTO Image (image_url, description) VALUES ('{image_url}', '{image_description}');\"\n",
    "    sql_commands.append(image_sql)\n",
    "\n",
    "    cook_sql = f\"\"\"INSERT INTO Cook (first_name, last_name, contact_number, date_of_birth, years_of_experience, ranking, username, password, image_id) VALUES\n",
    "    ('{first_name}', '{last_name}', '{contact_number}', '{date_of_birth}', {years_of_experience}, '{ranking}', '{username}', '{password}', {image_id});\"\"\"\n",
    "    sql_commands.append(cook_sql)\n",
    "        \n",
    "    user_sql = f\"\"\"CREATE USER '{username}' IDENTIFIED BY '{password}';\"\"\"\n",
    "    role_sql = f\"\"\"GRANT 'Cook_User' TO '{username}';\"\"\"\n",
    "    set_role = f\"\"\"SET DEFAULT ROLE \"Cook_User\" FOR '{username}';\"\"\"\n",
    "    sql_commands.append(user_sql)\n",
    "    sql_commands.append(role_sql)\n",
    "    sql_commands.append(set_role)\n",
    "        \n",
    "    image_id += 1\n",
    "\n",
    "    for i in range(2, num_males + 1):\n",
    "        first_name = fake.first_name_male()\n",
    "        last_name = fake.last_name_male()\n",
    "        contact_number = fake.phone_number()\n",
    "        date_of_birth = fake.date_of_birth(minimum_age=18, maximum_age=65).isoformat()\n",
    "        years_of_experience = random.randint(0, 30)\n",
    "        ranking = determine_ranking(years_of_experience)\n",
    "        username = f\"{first_name.lower()}{last_name.lower()}{random.randint(10, 99)}\"\n",
    "        password = fake.password(length=10, special_chars=True, digits=True, upper_case=True, lower_case=True)\n",
    "        \n",
    "        image_url = f\"{male_img_base_url}{i}.jpg\"\n",
    "        image_description = f\"This is an image for cook {first_name} {last_name}\"\n",
    "        image_sql = f\"INSERT INTO Image (image_url, description) VALUES ('{image_url}', '{image_description}');\"\n",
    "        sql_commands.append(image_sql)\n",
    "\n",
    "        cook_sql = f\"\"\"INSERT INTO Cook (first_name, last_name, contact_number, date_of_birth, years_of_experience, ranking, username, password, image_id) VALUES\n",
    "        ('{first_name}', '{last_name}', '{contact_number}', '{date_of_birth}', {years_of_experience}, '{ranking}', '{username}', '{password}', {image_id});\"\"\"\n",
    "        sql_commands.append(cook_sql)\n",
    "        \n",
    "        user_sql = f\"\"\"CREATE USER '{username}' IDENTIFIED BY '{password}';\"\"\"\n",
    "        role_sql = f\"\"\"GRANT 'Cook_User' TO '{username}';\"\"\"\n",
    "        set_role = f\"\"\"SET DEFAULT ROLE \"Cook_User\" FOR '{username}';\"\"\"\n",
    "        sql_commands.append(user_sql)\n",
    "        sql_commands.append(role_sql)\n",
    "        sql_commands.append(set_role)\n",
    "        \n",
    "        image_id += 1\n",
    "\n",
    "    for i in range(1, num_females + 1):\n",
    "        first_name = fake.first_name_female()\n",
    "        last_name = fake.last_name_female()\n",
    "        contact_number = fake.msisdn()[-10:]\n",
    "        date_of_birth = fake.date_of_birth(minimum_age=18, maximum_age=65).isoformat()\n",
    "        years_of_experience = random.randint(0, 30)\n",
    "        ranking = determine_ranking(years_of_experience)\n",
    "        username = f\"{first_name.lower()}{last_name.lower()}{random.randint(10, 99)}\"\n",
    "        password = fake.password(length=10, special_chars=True, digits=True, upper_case=True, lower_case=True)\n",
    "        \n",
    "        image_url = f\"{female_img_base_url}{i}.jpg\"\n",
    "        image_description = f\"\"\"This is an image for cook {first_name} {last_name}\"\"\"\n",
    "        image_sql = f\"\"\"INSERT INTO Image (image_url, description) VALUES ('{image_url}', '{image_description}');\"\"\"\n",
    "        sql_commands.append(image_sql)\n",
    "\n",
    "        cook_sql = f\"\"\"INSERT INTO Cook (first_name, last_name, contact_number, date_of_birth, years_of_experience, ranking, username, password, image_id) VALUES\n",
    "        ('{first_name}', '{last_name}', '{contact_number}', '{date_of_birth}', {years_of_experience}, '{ranking}', '{username}', '{password}', {image_id});\"\"\"\n",
    "        sql_commands.append(cook_sql)\n",
    "        \n",
    "        user_sql = f\"\"\"CREATE USER '{username}' IDENTIFIED BY '{password}';\"\"\"\n",
    "        role_sql = f\"\"\"GRANT 'Cook_User' TO '{username}';\"\"\"\n",
    "        set_role = f\"\"\"SET DEFAULT ROLE \"Cook_User\" FOR '{username}';\"\"\"\n",
    "        sql_commands.append(user_sql)\n",
    "        sql_commands.append(role_sql)\n",
    "        sql_commands.append(set_role)\n",
    "        \n",
    "        image_id += 1\n",
    "\n",
    "    return sql_commands, image_id\n",
    "\n",
    "sql_cooks, image_id = generate_cooks(50, 50, male_img_base_url, female_img_base_url, last_image_id)\n",
    "total_cooks = 100\n",
    "last_image_id = image_id\n",
    "with open(file_path + 'insert_data.sql', 'a', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_cooks))\n",
    "    file.write('\\n')\n",
    "\n",
    "print(\"Cook insertion queries have been saved to 'insert_data.sql'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b58c41",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "TOPICS !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0c6b432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic insertion queries have been saved to 'insert_data.sql'.\n"
     ]
    }
   ],
   "source": [
    "topics = [\n",
    "    (\"Village Recipes\", \"Traditional recipes from the village.\", \"https://www.yummytummyaarthi.com/wp-content/uploads/2016/04/1-9.jpg\"),\n",
    "    (\"Risotto Recipes\", \"Creamy and comforting risotto dishes.\", \"https://hips.hearstapps.com/del.h-cdn.co/assets/17/35/1600x1600/square-1504128527-delish-mushroom-risotto.jpg?resize=1200:*\"),\n",
    "    (\"Easter Sweets\", \"Delicious sweets perfect for Easter.\", \"https://www.readyseteat.com/sites/g/files/qyyrlu501/files/uploadedImages/img_9708_89897.jpg\"),\n",
    "    (\"Summer Salads\", \"Refreshing salads for hot days.\", \"https://images.immediate.co.uk/production/volatile/sites/30/2022/06/Epic-summer-salad-3aeb697.jpg\"),\n",
    "    (\"Winter Soups\", \"Hearty soups to warm you up.\", \"https://images.immediate.co.uk/production/volatile/sites/2/2017/10/Mushroom-Soup-2df69df.jpg?quality=90&resize=556,505\"),\n",
    "    (\"Vegan Dishes\", \"Tasty vegan recipes for all.\", \"https://images.immediate.co.uk/production/volatile/sites/30/2023/01/Ponzu-tofu-poke-bowl-8733c67.jpg?quality=90&resize=440,400\"),\n",
    "    (\"Quick Snacks\", \"Quick and easy snacks on the go.\", \"https://static.toiimg.com/photo/65163740.cms\"),\n",
    "    (\"Holiday Meals\", \"Festive meals for holiday celebrations.\", \"https://shop.momofuku.com/cdn/shop/articles/Holidays_2021_Table_Spread_3.jpg?v=1636317855\"),\n",
    "    (\"Dessert Ideas\", \"Creative desserts to impress.\", \"https://www.tasteofhome.com/wp-content/uploads/2018/01/exps21585_THCA153054D10_15_4b.jpg\"),\n",
    "    (\"Healthy Smoothies\", \"Nutritious smoothies for a health boost.\", \"https://www.eatingwell.com/thmb/CokPYaf2YPnPACHBls_LVhyUp0g=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/healthy-breakfast-smoothie-8029983-4000x4000-3e02d40929c8410c877a171a235c99bc.jpg\"),\n",
    "    (\"BBQ Grilling\", \"Best recipes for BBQ grilling.\", \"https://fnsharp.com/cdn/shop/articles/backyard-bbq-meat-grilling-guide-850x600_850x.jpg?v=1617738809\"),\n",
    "    (\"Seafood Specials\", \"Fresh and delicious seafood dishes.\", \"https://www.homemadeitaliancooking.com/wp-content/uploads/2018/12/plated_cioppino.jpg\"),\n",
    "    (\"Pasta Favorites\", \"Classic pasta recipes loved by all.\", \"https://www.foodandwine.com/thmb/tAS-x_IC4ss1cb9EdDpsr0UExdM=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/bucatini-with-mushroom-ragu-dandelion-greens-and-tarragon-FT-RECIPE0421-3a5f0d29f7264f5e9952d4a3a51f5f58.jpg\"),\n",
    "    (\"Breakfast Options\", \"Start your day right with these breakfasts.\", \"https://www.eatingwell.com/thmb/t1T6R6ZAyG6j8-39Bdmh6eAr0F4=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/egg-tartine-892cac2657114696ab634792d0bdcb4b.jpg\"),\n",
    "    (\"Comfort Food\", \"Food that feels like a hug.\", \"https://www.allrecipes.com/thmb/4h5yzzM5u5_Pgx6zoazspPPCZJg=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/237311-Slow-cooker-mac-and-cheese-ddmfs-1X1-1297-1-d5968b9dc757411fb6a973d37b311166.jpg\"),\n",
    "    (\"Street Food Adventures\", \"Bold flavors from around the world.\", \"https://afar.brightspotcdn.com/dims4/default/5d22728/2147483647/strip/false/crop/2500x1667+0+0/resize/1486x991!/quality/90/?url=https%3A%2F%2Fafar-media-production-web.s3.us-west-2.amazonaws.com%2Fbrightspot%2Fda%2Ff3%2F1894b566a3721db50ec473fcf399%2Foriginal-shutterstock-1294137358.jpg\"),\n",
    "    (\"Gluten-Free Goodies\", \"Delicious recipes without gluten.\", \"https://www.eatthis.com/wp-content/uploads/sites/4/2020/08/weldon-owen-gluten-free-cover.jpg?quality=82&strip=1\"),\n",
    "    (\"Low-Carb Meals\", \"Tasty low-carb options for healthy eating.\", \"https://www.eatingwell.com/thmb/XF2id3sTOpQwtVx0A6Z_y7cHqdI=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/cheesy-portobello-chicken-cutlets-with-broccoli-ae1449c758834bb7ac75437e37a14065.jpg\"),\n",
    "    (\"Midnight Munchies\", \"Perfect for late-night cravings.\", \"https://img.cdn4dd.com/cdn-cgi/image/fit=cover,width=600,height=400,format=auto,quality=80/https://doordash-static.s3.amazonaws.com/media/store/header/6e298dc7-f46e-4ae8-8d6d-91722c0d7ea4.JPG\")\n",
    "]\n",
    "\n",
    "def generate_topic_sql(topics, last_image_id, topic_dict):\n",
    "    sql_commands = []\n",
    "    image_id = last_image_id\n",
    "    topic_id = 1\n",
    "    \n",
    "    for name, description, image_url in topics:\n",
    "        image_description = f\"This is a theme image for {name}\"\n",
    "        \n",
    "        image_sql = f\"INSERT INTO Image (image_url, description) VALUES ('{image_url}', '{image_description}');\"\n",
    "        sql_commands.append(image_sql)\n",
    "        \n",
    "        topic_sql = f\"\"\"INSERT INTO Topic (name, description, image_id) VALUES\n",
    "        ('{name}', '{description}', {image_id});\"\"\"\n",
    "        sql_commands.append(topic_sql)\n",
    "        \n",
    "        topic_dict[topic_id] = name\n",
    "        topic_id += 1\n",
    "        image_id += 1\n",
    "\n",
    "    return sql_commands, image_id, topic_dict\n",
    "\n",
    "\n",
    "topic_dict = {}\n",
    "sql_topic_commands, new_image_id, topic_dict = generate_topic_sql(topics, last_image_id, topic_dict)\n",
    "last_image_id = new_image_id\n",
    "\n",
    "with open(file_path + 'insert_data.sql', 'a', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_topic_commands))\n",
    "    file.write('\\n')\n",
    "\n",
    "print(\"Topic insertion queries have been saved to 'insert_data.sql'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdc1ec2",
   "metadata": {},
   "source": [
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "RECIPES !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358a386",
   "metadata": {},
   "source": [
    "This function gets the url from the small json file (that has less info) and gets the full data from the database for a specific recipe based on its url (that can be found on the small url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0e338cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_recipe(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status() \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        scripts = soup.find_all('script', type='application/ld+json')\n",
    "        for script in scripts:\n",
    "            try:\n",
    "                data = json.loads(script.string)\n",
    "\n",
    "                if '@type' in data and data['@type'] == 'Recipe':\n",
    "                    return data\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb5cefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_duration(duration):\n",
    "    \"\"\" Parse ISO 8601 duration into minutes. \"\"\"\n",
    "    match = re.match(r'P(?:(\\d+)D)?T(?:(\\d+)H)?(?:(\\d+)M)?', duration)\n",
    "    days = int(match.group(1) or 0)\n",
    "    hours = int(match.group(2) or 0)\n",
    "    minutes = int(match.group(3) or 0)\n",
    "    return days * 1440 + hours * 60 + minutes\n",
    "\n",
    "def infer_recipe_type(description):\n",
    "    \"\"\" Infer recipe type based on description or ingredients. \"\"\"\n",
    "    keywords = {'pastry': ['flour', 'bake', 'oven'], 'cooking': ['fry', 'boil', 'grill']}\n",
    "    for type_, clues in keywords.items():\n",
    "        if any(clue in description.lower() for clue in clues):\n",
    "            return type_\n",
    "    return 'cooking' \n",
    "\n",
    "def infer_difficulty(preptime, cooktime):\n",
    "    \"\"\" Infer difficulty based on preparation and cooking times on a scale from 1 to 5. \"\"\"\n",
    "    total_time = preptime + cooktime\n",
    "    if total_time <= 20:\n",
    "        return 1 \n",
    "    elif total_time <= 40:\n",
    "        return 2 \n",
    "    elif total_time <= 60:\n",
    "        return 3 \n",
    "    elif total_time <= 120:\n",
    "        return 4 \n",
    "    else:\n",
    "        return 5  \n",
    "\n",
    "def extract_numbers(text):\n",
    "    \"\"\" Extract the first number from a string. \"\"\"\n",
    "    numbers = re.findall(r'\\d+', text)\n",
    "    return int(numbers[0]) if numbers else 1 \n",
    "\n",
    "def random_nutritional_value(min_value, max_value):\n",
    "    \"\"\" Generate a random float within given range, formatted to two decimal places. \"\"\"\n",
    "    return round(random.uniform(min_value, max_value), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8d33f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nationality_id_from_cuisine(cuisine, nationality_dict):\n",
    "    if cuisine:\n",
    "        matches = process.extractOne(cuisine, list(nationality_dict.values()), score_cutoff=80) #80\n",
    "        if matches:\n",
    "            return next(key for key, value in nationality_dict.items() if value == matches[0])\n",
    "    return random.randint(1, len(nationality_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ef2d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_ingredient(ingredient_name):\n",
    "\n",
    "    qualifiers = [\n",
    "        'fresh', 'chopped', 'diced', 'sliced', 'ground', 'crushed', 'canned',\n",
    "        'tsp', 'tbsp', 'cup', 'cups', 'ml', 'g', 'small', 'medium', 'large',\n",
    "        'minced', 'peeled', 'washed', 'dried'\n",
    "    ]\n",
    "    words = ingredient_name.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in qualifiers]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def find_closest_food_match(ingredient_name, food_df):\n",
    "    processed_ingredient = preprocess_ingredient(ingredient_name)\n",
    "    \n",
    "\n",
    "    matches = process.extract(processed_ingredient, food_df['Food'], scorer=fuzz.token_set_ratio, limit=3)\n",
    "\n",
    "    for match, score, _ in matches:  \n",
    "        if score >= 90:\n",
    "            if 'medium' in processed_ingredient and 'medium' not in match:\n",
    "                continue \n",
    "            return match  \n",
    "\n",
    "    if matches:\n",
    "        return matches[0][0]  \n",
    "    \n",
    "    return \"No close match found\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ea50362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredient: cups flour, Quantity Type: serving, Quantity: 3.0, Serving Type: cups\n"
     ]
    }
   ],
   "source": [
    "def parse_ingredient(ingredient):\n",
    "    \n",
    "    fraction_dict = {\n",
    "        '½': 0.5, '⅓': 1/3, '¼': 0.25, '⅔': 2/3,\n",
    "        '¾': 0.75, '⅛': 0.125, '⅜': 0.375,\n",
    "        '⅝': 0.625, '⅞': 0.875\n",
    "    }\n",
    "    non_numeric_words = [\"some\", \"a lot of\", \"much\", \"enough\", \"a pinch of\", \"few\"]\n",
    "\n",
    "    ingredient = ingredient.split(',')[0].strip()\n",
    "    ingredient = re.sub(r'oz|/lb|/1lb|/fl', '', ingredient).strip()\n",
    "\n",
    "    quantity_unit_pattern = r\"(\\d+\\.?\\d*|\\d*\\s*\\d/\\d|½|⅓|¼|⅔|¾|⅛|⅜|⅝|⅞)\\s*(ml|g\\b|gr\\b)?\"\n",
    "    match = re.search(quantity_unit_pattern, ingredient, re.IGNORECASE)\n",
    "    \n",
    "    serving_type = None\n",
    "\n",
    "    if match:\n",
    "        quantity = match.group(1)\n",
    "        unit = match.group(2)\n",
    "\n",
    "        if quantity in fraction_dict:\n",
    "            quantity = fraction_dict[quantity]\n",
    "        else:\n",
    "            try:\n",
    "                quantity = float(Fraction(quantity))\n",
    "            except (ValueError, TypeError):\n",
    "                quantity = None  \n",
    "\n",
    "        remaining_text = re.sub(quantity_unit_pattern, '', ingredient).strip()\n",
    "        possible_units = ['cups', 'cup', 'tbsp', 'tsp', 'pinch', 'cloves', 'clove']\n",
    "        for possible_unit in possible_units:\n",
    "            if possible_unit in remaining_text.split():\n",
    "                serving_type = possible_unit\n",
    "                break\n",
    "\n",
    "        if unit in ['g', 'ml']:\n",
    "            quantity_type = 'grams'\n",
    "        elif unit or serving_type:\n",
    "            quantity_type = 'serving'\n",
    "            serving_type = unit or serving_type\n",
    "        else:\n",
    "            quantity_type = 'serving'\n",
    "\n",
    "        ingredient_name = remaining_text\n",
    "    else:\n",
    "        quantity = random.choice(non_numeric_words)\n",
    "        quantity_type = 'non_numeric'\n",
    "        ingredient_name = ingredient.strip()\n",
    "\n",
    "    return ingredient_name, quantity_type, quantity, serving_type\n",
    "\n",
    "# Example usage\n",
    "example_ingredient = \"3 ½ cups flour\"\n",
    "ingredient_name, quantity_type, quantity, serving_type = parse_ingredient(example_ingredient)\n",
    "print(f'Ingredient: {ingredient_name}, Quantity Type: {quantity_type}, Quantity: {quantity}, Serving Type: {serving_type}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fc16537",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching http://www.seriouseats.com/recipes/2008/11/the-slope-recipe-drink-brooklyn-clover-club.html: 406 Client Error: Not Acceptable for url: https://www.seriouseats.com/recipes/2008/11/the-slope-recipe-drink-brooklyn-clover-club.html\n",
      "Error fetching http://www.seriouseats.com/recipes/2008/02/cocktails-red-hook-recipe.html: 405 Client Error: Signal - Not Acceptable for url: http://www.seriouseats.com/recipes/2008/02/cocktails-red-hook-recipe.html\n",
      "Error fetching http://www.seriouseats.com/recipes/2007/12/dinner-tonight-balsamic-glazed-brussels-sprouts-recipe.html: 405 Client Error: Signal - Not Acceptable for url: http://www.seriouseats.com/recipes/2007/12/dinner-tonight-balsamic-glazed-brussels-sprouts-recipe.html\n",
      "Error fetching http://www.seriouseats.com/recipes/2008/02/cocktails-widows-kiss-recipe.html: 405 Client Error: Signal - Not Acceptable for url: http://www.seriouseats.com/recipes/2008/02/cocktails-widows-kiss-recipe.html\n",
      "Error fetching http://www.seriouseats.com/recipes/2007/12/cartoon-kitchen-oranges-campari.html: 405 Client Error: Signal - Not Acceptable for url: http://www.seriouseats.com/recipes/2007/12/cartoon-kitchen-oranges-campari.html\n",
      "Error fetching http://www.bbc.co.uk/food/recipes/zebra_cake_76226: 404 Client Error: Not Found for url: https://www.bbc.co.uk/food/recipes/zebra_cake_76226\n",
      "Error fetching http://www.bbc.co.uk/food/recipes/pan-fried_cod_with_69476: 404 Client Error: Not Found for url: https://www.bbc.co.uk/food/recipes/pan-fried_cod_with_69476\n",
      "Error fetching http://www.bbc.co.uk/food/recipes/jennysbarbecuesparer_70172: 404 Client Error: Not Found for url: https://www.bbc.co.uk/food/recipes/jennysbarbecuesparer_70172\n",
      "Error fetching http://www.bbc.co.uk/food/recipes/goosnargh_biscuits_with_79879: 404 Client Error: Not Found for url: https://www.bbc.co.uk/food/recipes/goosnargh_biscuits_with_79879\n",
      "Error fetching http://www.bbc.co.uk/food/recipes/yorkshire_scones_with_67876: 404 Client Error: Not Found for url: https://www.bbc.co.uk/food/recipes/yorkshire_scones_with_67876\n",
      "Error fetching http://www.bbc.co.uk/food/recipes/lancashire_cheese_and_31588: 404 Client Error: Not Found for url: https://www.bbc.co.uk/food/recipes/lancashire_cheese_and_31588\n",
      "Error fetching http://www.bbc.co.uk/food/recipes/egg_mayonnaise_and_67780: 404 Client Error: Not Found for url: https://www.bbc.co.uk/food/recipes/egg_mayonnaise_and_67780\n",
      "Error fetching http://www.bbc.co.uk/food/recipes/traditional_spring_67057: 404 Client Error: Not Found for url: https://www.bbc.co.uk/food/recipes/traditional_spring_67057\n",
      "Error fetching http://www.bbc.co.uk/food/recipes/stuffedbabypeppers_67844: 404 Client Error: Not Found for url: https://www.bbc.co.uk/food/recipes/stuffedbabypeppers_67844\n",
      "Error fetching http://www.bbc.co.uk/food/recipes/strawberry_saffron_dip_83441: 404 Client Error: Not Found for url: https://www.bbc.co.uk/food/recipes/strawberry_saffron_dip_83441\n",
      "Error fetching http://www.bbc.co.uk/food/recipes/bbq_beer-can_chicken_80142: 404 Client Error: Not Found for url: https://www.bbc.co.uk/food/recipes/bbq_beer-can_chicken_80142\n"
     ]
    }
   ],
   "source": [
    "recipes = []\n",
    "image_id = last_image_id\n",
    "with open(file_path + 'recipeitems-latest.json', 'r', encoding='utf-8') as file:\n",
    "    while len(recipes) < 100:\n",
    "        line = file.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        try:\n",
    "            recipe_meta = json.loads(line)\n",
    "            if (not recipe_meta.get('image')) or recipe_meta.get('image').startswith(\"http://static.thepioneerwoman.com\") or recipe_meta.get('image').startswith(\"http://cdn.naturallyella.com\"):\n",
    "                continue\n",
    "            url = recipe_meta.get('url') \n",
    "            if url:\n",
    "                if url.startswith(\"http://www.bonappetit.com\") or url.startswith(\"https://www.aspicyperspective.com\") or url.startswith(\"http://delishhh.com\"):\n",
    "                    continue\n",
    "                recipe = scrape_recipe(url)\n",
    "                if recipe:\n",
    "                    recipe['image'] = recipe_meta.get('image')\n",
    "                    recipe['yield'] = recipe_meta.get('image')\n",
    "                    if not all([recipe.get('name'), recipe.get('description'), recipe.get('image'), recipe.get('prepTime'), recipe.get('cookTime'), recipe.get('recipeInstructions'), recipe.get('recipeIngredient'), recipe.get('recipeCuisine'), recipe.get('recipeCategory'), recipe.get('recipeYield')]):\n",
    "                        continue\n",
    "                    recipes.append(recipe)\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af849ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Meal Types: 15\n",
      "Total Tags: 30\n",
      "Total Tips: 15\n"
     ]
    }
   ],
   "source": [
    "def generate_sql_and_dict(entries, table_name):\n",
    "    sql_commands = []\n",
    "    entry_dict = {}\n",
    "    for idx, entry in enumerate(entries, start=1):\n",
    "        sql_commands.append(f\"INSERT INTO {table_name} (name) VALUES ('{entry}');\")\n",
    "        entry_dict[idx] = entry\n",
    "    return sql_commands, len(entries), entry_dict\n",
    "\n",
    "# Meal types\n",
    "meal_types = [\n",
    "    'breakfast', 'brunch', 'second breakfast', 'elevenses', 'lunch', 'tea',\n",
    "    'dinner', 'supper', 'late-night snack', 'midnight meal', 'holiday feast',\n",
    "    'weekend dinner', 'light snack', 'afternoon snack', 'pre-workout meal'\n",
    "]\n",
    "\n",
    "# Tags\n",
    "tags = [\n",
    "    'quick-lunch', 'cold-dish', 'vegetarian', 'low-carb', 'family-friendly', 'quick', 'healthy',\n",
    "    'gluten-free', 'vegan', 'no-cook', 'make-ahead', 'one-pot', 'summer', 'winter', 'festive',\n",
    "    'comfort food', 'low-fat', 'high-protein', 'kid-friendly', 'budget-friendly', 'party', 'gourmet',\n",
    "    'starters & nibbles', 'other', 'desserts', 'main course', 'light meals & snacks',\n",
    "    'cakes and baking', 'side dishes', 'brunch'\n",
    "]\n",
    "\n",
    "# Tips\n",
    "tips = [\n",
    "    \"Can be stored in the refrigerator for up to 3 days.\",\n",
    "    \"Best served hot.\",\n",
    "    \"Can be frozen for one month.\",\n",
    "    \"Prep the night before for quicker assembly.\",\n",
    "    \"Adjust spices to taste.\",\n",
    "    \"Add a splash of lemon for extra zest.\",\n",
    "    \"Keep hydrated while cooking.\",\n",
    "    \"Taste as you go.\",\n",
    "    \"Use fresh herbs for better flavor.\",\n",
    "    \"Clean as you cook to save time.\",\n",
    "    \"Marinate overnight for deeper flavor.\",\n",
    "    \"Serve with crusty bread to complement the dish.\",\n",
    "    \"Perfect for batch cooking.\",\n",
    "    \"Garnish with fresh greens for added color.\",\n",
    "    \"A pinch of sugar can balance acidity.\"\n",
    "]\n",
    "\n",
    "meal_type_sql, meal_type_count, meal_type_dict = generate_sql_and_dict(meal_types, \"Meal_type\")\n",
    "tag_sql, tag_count, tags_dict = generate_sql_and_dict(tags, \"Tag\")\n",
    "tip_sql, tip_count, tips_dict = generate_sql_and_dict(tips, \"Tip\")\n",
    "\n",
    "# Writing to SQL file\n",
    "with open(file_path + 'insert_data.sql', 'a', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(meal_type_sql))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n'.join(tag_sql))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n'.join(tip_sql))\n",
    "    file.write('\\n')\n",
    "\n",
    "print(f\"Total Meal Types: {meal_type_count}\")\n",
    "print(f\"Total Tags: {tag_count}\")\n",
    "print(f\"Total Tips: {tip_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f469fc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nationality_Cook insertion queries have been saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikol\\AppData\\Local\\Temp\\ipykernel_6768\\2178677979.py:17: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  mandatory_nationalities = random.sample(nationality_ids_from_recipes, random.randint(4, 7))\n"
     ]
    }
   ],
   "source": [
    "nationality_cook_dict = {}\n",
    "\n",
    "nationality_ids_from_recipes = set()\n",
    "for recipe in recipes:\n",
    "    nationality_id = get_nationality_id_from_cuisine(recipe['recipeCuisine'], nationality_dict)\n",
    "    nationality_ids_from_recipes.add(nationality_id)\n",
    "\n",
    "all_nationality_ids = set(nationality_dict.keys())\n",
    "\n",
    "additional_nationality_ids = list(all_nationality_ids - nationality_ids_from_recipes)\n",
    "\n",
    "sql_commands = []\n",
    "#total_cooks = 100 from cooks generation\n",
    "cook_ids = range(1, total_cooks + 1)  \n",
    "\n",
    "for cook_id in cook_ids:\n",
    "    mandatory_nationalities = random.sample(nationality_ids_from_recipes, random.randint(4, 7))\n",
    "    nationality_cook_dict[cook_id] = mandatory_nationalities\n",
    "\n",
    "    additional_nationalities = random.sample(additional_nationality_ids, random.randint(4, 9))\n",
    "    total_nationalities = mandatory_nationalities + additional_nationalities\n",
    "\n",
    "    for nationality_id in total_nationalities:\n",
    "        sql_command = f\"\"\"INSERT INTO Nationality_Cook (nationality_id, cook_id) VALUES ({nationality_id}, {cook_id});\"\"\"\n",
    "        sql_commands.append(sql_command)\n",
    "\n",
    "with open(file_path + 'insert_data.sql', 'a', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "    file.write('\\n')\n",
    "\n",
    "print(\"Nationality_Cook insertion queries have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7a3d3a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL generation complete. All insertion queries have been saved to 'insert_data.sql'.\n"
     ]
    }
   ],
   "source": [
    "sql_commands = []\n",
    "recipe_id = 1\n",
    "image_id = last_image_id\n",
    "recipe_nationality_dict = {}\n",
    "\n",
    "for recipe in recipes:\n",
    "    name = recipe['name'].replace(\"'\", \"''\")\n",
    "    description = recipe['description'].replace(\"'\", \"''\")\n",
    "    description = description.replace(\"’\", \"''\")\n",
    "    image_url = recipe['image']\n",
    "    prep_time = parse_duration(recipe.get('prepTime', 'PT0M'))\n",
    "    cook_time = parse_duration(recipe.get('cookTime', 'PT0M'))\n",
    "    portions = extract_numbers(recipe.get('recipeYield', '1'))\n",
    "    difficulty = infer_difficulty(prep_time, cook_time)\n",
    "    ingredients = recipe['recipeIngredient']\n",
    "    steps = recipe['recipeInstructions']\n",
    "    nationality = recipe['recipeCuisine']\n",
    "    category = recipe['recipeCategory']\n",
    "    \n",
    "    if 'Cakes and baking' == category or 'Desserts' == category:\n",
    "        recipe_type = 'pastry'\n",
    "    else:\n",
    "        recipe_type = 'cooking'\n",
    "\n",
    "    fat_grams_per_portion = random_nutritional_value(5, 30)\n",
    "    protein_grams_per_portion = random_nutritional_value(10, 50)\n",
    "    curbs_grams_per_portion = random_nutritional_value(20, 100)\n",
    "    kcal_per_portion = '0.00'\n",
    "    \n",
    "    image_id += 1\n",
    "    image_description = f\"This is an image for {name}.\"\n",
    "    image_sql = f\"INSERT INTO Image (image_url, description) VALUES ('{image_url}', '{image_description}');\"\n",
    "    sql_commands.append(image_sql)\n",
    "    \n",
    "    nationality_id = get_nationality_id_from_cuisine(recipe['recipeCuisine'], nationality_dict)\n",
    "    recipe_nationality_dict[recipe_id] = nationality_id\n",
    "    sql = f\"\"\"INSERT INTO Recipe (recipe_type, difficulty, name, description, preparation_time, execution_time, portions, fat_grams_per_portion, protein_grams_per_portion, curbs_grams_per_portion, kcal_per_portion, image_id, nationality_id) VALUES ('{recipe_type}', {difficulty}, '{name}', '{description}', {prep_time}, {cook_time}, {portions}, {fat_grams_per_portion}, {protein_grams_per_portion}, {curbs_grams_per_portion}, {kcal_per_portion}, {image_id}, {nationality_id});\"\"\"\n",
    "    sql_commands.append(sql)\n",
    "    \n",
    "    basic_ingredient_selected = False\n",
    "    used_ingredient_ids = set()\n",
    "    for ingredient in ingredients:\n",
    "        ingredient_name, quantity_type, quantity, serving_type = parse_ingredient(ingredient)\n",
    "        matched_ingredient = find_closest_food_match(ingredient_name, final_food_df)\n",
    "        ingredient_id = ingredient_dict.get(matched_ingredient)\n",
    "        \n",
    "        if ingredient_id in used_ingredient_ids:\n",
    "            continue\n",
    "\n",
    "        used_ingredient_ids.add(ingredient_id)\n",
    "\n",
    "        if ingredient_id:\n",
    "            basic_ingredient = 'FALSE'\n",
    "            if not basic_ingredient_selected:\n",
    "                basic_ingredient = 'TRUE'\n",
    "                basic_ingredient_selected = True\n",
    "            \n",
    "            ingredient_sql = f\"\"\"INSERT INTO Recipe_Ingredient (recipe_id, ingredient_id, basic_ingredient, quantity_type, quantity, serving_type) VALUES ({recipe_id}, {ingredient_id}, {basic_ingredient}, '{quantity_type}', '{quantity}', '{serving_type}');\"\"\"\n",
    "            sql_commands.append(ingredient_sql)\n",
    "            \n",
    "            \n",
    "    num_equipment = random.randint(5, 8)\n",
    "    chosen_equipment_ids = random.sample(list(equipment_dict.keys()), num_equipment)\n",
    "    for equipment_id in chosen_equipment_ids:\n",
    "        equipment_sql = f\"\"\"INSERT INTO Recipe_Equipment (recipe_id, equipment_id) VALUES ({recipe_id}, {equipment_id});\"\"\"\n",
    "        sql_commands.append(equipment_sql)\n",
    "        \n",
    "    num_topic = random.randint(1, 3)\n",
    "    chosen_topic_ids = random.sample(list(topic_dict.keys()), num_topic)\n",
    "    for topic_id in chosen_topic_ids:\n",
    "        topic_sql = f\"\"\"INSERT INTO Recipe_Topic (recipe_id, topic_id) VALUES ({recipe_id}, {topic_id});\"\"\"\n",
    "        sql_commands.append(topic_sql)\n",
    "    \n",
    "    sequence = 1  \n",
    "    for step in steps:\n",
    "        step_description = step.replace(\"'\", \"''\")\n",
    "        step_description = step_description.replace(\"’\", \"''\")\n",
    "        step_sql = f\"\"\"INSERT INTO Step (recipe_id, name, sequence) VALUES ({recipe_id}, '{step_description}', {sequence});\"\"\"\n",
    "        sql_commands.append(step_sql)\n",
    "        sequence += 1 \n",
    "        \n",
    "    assigned_meal_type_ids = random.sample(range(1, meal_type_count + 1), random.randint(1, 3))\n",
    "    for meal_type_id in assigned_meal_type_ids:\n",
    "        meal_type_sql = f\"INSERT INTO Recipe_Meal_Type (recipe_id, meal_type_id) VALUES ({recipe_id}, {meal_type_id});\"\n",
    "        sql_commands.append(meal_type_sql)\n",
    "\n",
    "    category_id = None\n",
    "    for tag_id, tag_name in tags_dict.items():\n",
    "        if tag_name == category.lower():\n",
    "            category_id = tag_id\n",
    "            break\n",
    "    \n",
    "    if category_id is None:\n",
    "        assigned_tag_ids = random.sample(range(1, tag_count + 1), random.randint(1, 3))\n",
    "    else:\n",
    "        available_tag_ids = [tid for tid in range(1, tag_count + 1) if tid != category_id]\n",
    "        additional_tag_ids = random.sample(available_tag_ids, random.randint(1, 3))\n",
    "        assigned_tag_ids = [category_id] + additional_tag_ids\n",
    "            \n",
    "    for tag_id in assigned_tag_ids:\n",
    "        tag_sql = f\"INSERT INTO Recipe_Tag (recipe_id, tag_id) VALUES ({recipe_id}, {tag_id});\"\n",
    "        sql_commands.append(tag_sql)\n",
    "\n",
    "    assigned_tip_ids = random.sample(range(1, tip_count + 1), random.randint(1, 3))\n",
    "    for tip_id in assigned_tip_ids:\n",
    "        tip_sql = f\"INSERT INTO Recipe_Tip (recipe_id, tip_id) VALUES ({recipe_id}, {tip_id});\"\n",
    "        sql_commands.append(tip_sql)\n",
    "        \n",
    "    recipe_id += 1  \n",
    "\n",
    "last_image_id = image_id\n",
    "last_recipe_id = recipe_id - 1\n",
    "\n",
    "with open(file_path + 'insert_data.sql', 'a', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "    file.write('\\n')\n",
    "\n",
    "print(\"SQL generation complete. All insertion queries have been saved to 'insert_data.sql'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c94647c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe_Cook insertion queries, including additional random recipes, have been saved.\n"
     ]
    }
   ],
   "source": [
    "#last_recipe_id = 100\n",
    "all_recipe_ids = list(range(1, last_recipe_id + 1))\n",
    "\n",
    "sql_commands = []\n",
    "\n",
    "for cook_id, nationalities in nationality_cook_dict.items():\n",
    "\n",
    "    recipes_for_cook = []\n",
    "\n",
    "    for recipe_id, recipe_nationality in recipe_nationality_dict.items():\n",
    "        if recipe_nationality in nationalities:\n",
    "            sql_command = f\"\"\"INSERT INTO Recipe_Cook (recipe_id, cook_id) VALUES ({recipe_id}, {cook_id});\"\"\"\n",
    "            sql_commands.append(sql_command)\n",
    "            recipes_for_cook.append(recipe_id)\n",
    "\n",
    "    available_recipes = list(set(all_recipe_ids) - set(recipes_for_cook))\n",
    "\n",
    "    if len(available_recipes) >= 10:\n",
    "        random_additional_recipes = random.sample(available_recipes, 10)\n",
    "    else:\n",
    "        random_additional_recipes = available_recipes\n",
    "\n",
    "    for additional_recipe_id in random_additional_recipes:\n",
    "        sql_command = f\"\"\"INSERT INTO Recipe_Cook (recipe_id, cook_id) VALUES ({additional_recipe_id}, {cook_id});\"\"\"\n",
    "        sql_commands.append(sql_command)\n",
    "\n",
    "with open(file_path + 'insert_data.sql', 'a', encoding='utf-8') as file:\n",
    "    file.write('\\n'.join(sql_commands))\n",
    "    file.write('\\n')\n",
    "\n",
    "print(\"Recipe_Cook insertion queries, including additional random recipes, have been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
